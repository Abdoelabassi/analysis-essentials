{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6: Neural networks\n",
    "\n",
    "**This tutorial is rather old and outdated. Today, use TensorFlow 2.x or PyTorch to create a neural network**\n",
    "\n",
    "Neural networks inside [hep_ml](https://github.com/arogozhnikov/hep_ml) are very simple, but flexible. They are using [theano](http://deeplearning.net/software/theano/) library.\n",
    "\n",
    "**hep_ml.nnet** also provides tools to optimize any continuos expression as a decision function (there is an example below). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading a dataset\n",
    "downloading dataset from UCI and splitting it into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "data = pandas.read_csv('https://cern.ch/starterkit/data/advanced-python-2019/MiniBooNE_PID.txt', sep='\\s\\s*', skiprows=[0], header=None, engine='python')\n",
    "labels = pandas.read_csv('https://cern.ch/starterkit/data/advanced-python-2019/MiniBooNE_PID.txt', sep=' ', nrows=1, header=None)\n",
    "labels = [1] * labels[1].values[0] + [0] * labels[2].values[0]\n",
    "data.columns = ['feature_{}'.format(key) for key in data.columns]\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, train_size=0.5, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of training a network\n",
    "Training multilayer perceptron with one hidden layer with 5 neurons. \n",
    "In most cases, we simply use `MLPClassifier` with one or two hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
      "/home/jonas/anaconda3/envs/starterkit38/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.neighbors.unsupervised module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(epochs=500, layers=[5])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hep_ml.nnet import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = MLPClassifier(layers=[5], epochs=500)\n",
    "clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test quality: 0.9717323609052467\n"
     ]
    }
   ],
   "source": [
    "proba = clf.predict_proba(test_data)\n",
    "print('Test quality:', roc_auc_score(test_labels, proba[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train quality: 0.9722966523910433\n"
     ]
    }
   ],
   "source": [
    "proba = clf.predict_proba(train_data)\n",
    "print('Train quality:', roc_auc_score(train_labels, proba[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating your own neural network\n",
    "\n",
    "To create own neural network, one should provide activation function and define parameters of a network.\n",
    "\n",
    "You are not limited here to any kind of structure in this function, **hep_ml.nnet** will consider this as a black box for optimization.\n",
    "\n",
    "Simplest way is to override `prepare` method of `AbstractNeuralNetworkClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hep_ml.nnet import AbstractNeuralNetworkClassifier\n",
    "from theano import tensor as T\n",
    "\n",
    "class SimpleNeuralNetwork(AbstractNeuralNetworkClassifier):\n",
    "    def prepare(self):\n",
    "        # getting number of layers in input, hidden, output layers\n",
    "        # note that we support only one hidden layer here\n",
    "        n1, n2, n3 = self.layers_\n",
    "        \n",
    "        # creating parameters of neural network\n",
    "        W1 = self._create_matrix_parameter('W1', n1, n2)\n",
    "        W2 = self._create_matrix_parameter('W2', n2, n3)\n",
    "        \n",
    "        # defining activation function\n",
    "        def activation(input):\n",
    "            first = T.nnet.sigmoid(T.dot(input, W1))\n",
    "            return T.dot(first, W2)\n",
    "\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test quality: 0.9716775521219609\n"
     ]
    }
   ],
   "source": [
    "clf = SimpleNeuralNetwork(layers=[5], epochs=500)\n",
    "clf.fit(train_data, train_labels)\n",
    "print('Test quality:', roc_auc_score(test_labels, clf.predict_proba(test_data)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of a very specific neural network\n",
    "this NN has one hidden layer, but the layer is quite strange, as it encounters correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test quality: 0.9685129126634252\n"
     ]
    }
   ],
   "source": [
    "from hep_ml.nnet import PairwiseNeuralNetwork\n",
    "clf = PairwiseNeuralNetwork(layers=[5], epochs=500)\n",
    "clf.fit(train_data, train_labels)\n",
    "print('Test quality:', roc_auc_score(test_labels, clf.predict_proba(test_data)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting very specific expressions as estimators\n",
    "One can use **hep_ml.nnet** to optimize any expressions as black-box\n",
    "for simplicity, let's assume we have only three variables: $\\text{var}_1, \\text{var}_2, \\text{var}_3.$\n",
    "\n",
    "And for some physical intuition we are sure that this is good expression to discriminate signal and background:\n",
    "$$\\text{output} = c_1 \\text{var}_1 + c_2 \\log \\left[ \\exp(\\text{var}_2 + \\text{var}_3) + \\exp(c_3) \\right] + c_4 \\dfrac{\\text{var}_3}{\\text{var}_2} + c_5 $$\n",
    "\n",
    "**Note**: I have written some random expression here, in practice it appears from physical intuition (or after looking at the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNeuralNetwork(AbstractNeuralNetworkClassifier):\n",
    "    def prepare(self):\n",
    "        # getting number of layers in input, hidden, output layers\n",
    "        # note that we support only one hidden layer here\n",
    "        n1, n2, n3 = self.layers_        \n",
    "        # checking that we have three variables in input + constant\n",
    "        assert n1 == 3 + 1 \n",
    "        # creating parameters\n",
    "        c1 = self._create_scalar_parameter('c1')\n",
    "        c2 = self._create_scalar_parameter('c2')\n",
    "        c3 = self._create_scalar_parameter('c3')\n",
    "        c4 = self._create_scalar_parameter('c4')\n",
    "        c5 = self._create_scalar_parameter('c5')\n",
    "        \n",
    "        # defining activation function\n",
    "        def activation(input):\n",
    "            v1, v2, v3 = input[:, 0], input[:, 1], input[:, 2]\n",
    "            return c1 * v1 + c2 * T.log(T.exp(v2 + v3) + T.exp(c3)) + c4 * v3 / v2 + c5\n",
    "        \n",
    "        return activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing custom pretransformer\n",
    "\n",
    "Below we define a very simple `scikit-learn` transformer which will transform each feature uniform to range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rep'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d1dca614e5af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlattener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mUniformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# leaving only 3 features and flattening each variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rep'"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from rep.utils import Flattener\n",
    "\n",
    "class Uniformer(BaseEstimator, TransformerMixin):\n",
    "    # leaving only 3 features and flattening each variable\n",
    "    def fit(self, X, y=None):\n",
    "        self.transformers = []\n",
    "        X = numpy.array(X, dtype=float)\n",
    "        for column in range(X.shape[1]):\n",
    "            self.transformers.append(Flattener(X[:, column]))\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X = numpy.array(X, dtype=float)\n",
    "        assert X.shape[1] == len(self.transformers)\n",
    "        for column, trans in enumerate(self.transformers):\n",
    "            X[:, column] = trans(X[:, column])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting three features to train: \n",
    "train_features = train_data.columns[:3]\n",
    "\n",
    "clf = CustomNeuralNetwork(layers=[5], epochs=1000, scaler=Uniformer())\n",
    "clf.fit(train_data[train_features], train_labels)\n",
    "\n",
    "print('Test quality:', roc_auc_score(test_labels, clf.predict_proba(test_data[train_features])[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling of neural neworks\n",
    "let's run AdaBoost algorithm over neural network. Boosting of the networks is rarely seen in practice due to the high cost and minor positive effects (but it is not senseless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "base_nnet = MLPClassifier(layers=[5], scaler=Uniformer())\n",
    "clf = AdaBoostClassifier(base_estimator=base_nnet, n_estimators=10)\n",
    "clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test quality:', roc_auc_score(test_labels, clf.predict_proba(test_data)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
